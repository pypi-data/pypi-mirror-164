{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polar-player",
   "metadata": {},
   "source": [
    "This notebook is a quick introduction to the sparse representation set out by M. Carrasco-Kind and R. J. Brunner in their paper arxiv.org:1404.6442. The original code is freely available here:https://github.com/mgckind/SparsePz together with the paper pdf and notebook tutorials. The code is not python3 compliant though.\n",
    "As a functional form for the representation basis, they used a Voigt profile, which generalizes a Gaussian to larger tails (It is in essence a convolution between a gaussian and a Cauchy distribution). This notebook exercizes the functionalities coded in the module qp/sparse_rep.py : look there for further comments on the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import qp\n",
    "import numpy as np\n",
    "from scipy import linalg as sla\n",
    "from scipy import special\n",
    "from scipy import integrate as sciint\n",
    "from scipy import interpolate as sciinterp\n",
    "from matplotlib import pylab as plt\n",
    "from astropy.io import fits as pf\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-september",
   "metadata": {},
   "source": [
    "We load the data : pdf examples from either qp or the original SparsePz package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntot = 10 #limit the number of pdfs for testing. Set to -1 to load all pdfs\n",
    "if True:\n",
    "    filein = './CFHTLens_sample.P.npy'\n",
    "    #FORMAT FILE, EACH ROW IS THE PDF FOR EACH GALAXY, LAST ROW IS THE REDSHIFT POSITION\n",
    "    P = np.load(filein)\n",
    "    z = P[-1]\n",
    "    ens_red = qp.Ensemble(qp.interp, data=dict(xvals=z, yvals=P[:Ntot]))\n",
    "\n",
    "else:\n",
    "    ens = qp.read('qp_test_ensemble.hdf5')\n",
    "    z = ens.metadata()['xvals'][0]\n",
    "    if Ntot != -1:\n",
    "        ens_red = ens[np.arange(Ntot)]\n",
    "    else:\n",
    "        ens_red = ens\n",
    "P = ens_red.objdata()['yvals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-modern",
   "metadata": {},
   "source": [
    "We want to enforce normalisation, just in case the input pdfs are not properly normalized, and we want to optimize the grid used for sparse representation over the whole considered sample (the same grid needs to be used for every pdf in the sample). We use trapezoidal rule as a fast integrator and likely a sufficient precision for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = P/sciint.trapz(P,z).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "minz = np.min(z)\n",
    "nz = 301\n",
    "i,j=np.where(P>0)\n",
    "maxz=np.max(z[j+1])\n",
    "newz=np.linspace(minz, maxz, nz)\n",
    "interp = sciinterp.interp1d(z,P, assume_sorted=True)\n",
    "newpdf = interp(newz)\n",
    "newpdf = newpdf / sciint.trapz(newpdf,newz).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check the pdfs if the Ntot is not too large\n",
    "#plt.plot(z,P.T); plt.plot(newz,newpdf.T,'-'); plt.xlim(minz,maxz);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-chosen",
   "metadata": {},
   "source": [
    "The following call builds the sparse representation: *Sparse_Indices* is the NobjxNsparse array of encoded indices (Nobj=number f object in the sample and Nsparse maximum number of bases used for the representation), *meta* is the metadata used to build the representation, and *A* is the Voigt nzxNbasis basis array (nz is the number of values where the bases are evaluated, and Nbasis is the number of bases used). *sparse_rep.build_sparse_representation* accepts several more arguments to define the basis array. This step takes 0.2s/object, and is trivially parallelizable over the set of object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sparse_Indices, meta, A = qp.sparse_rep.build_sparse_representation(newz, newpdf, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-workshop",
   "metadata": {},
   "source": [
    "When the basis array A is available, one can reconstruct the pdf without needing the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_y = qp.sparse_rep.pdf_from_sparse(Sparse_Indices, A, newz, cut=1.e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "plt.plot(newz, pdf_y[:,k], '.b')\n",
    "plt.plot(newz, newpdf[k], '-r')\n",
    "#plt.xlim((0.19,0.2))\n",
    "#plt.ylim((-0.1,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (pdf_y[:,k]-newpdf[k])/pdf_y[:,k]\n",
    "# remove numerical instability close to 0:\n",
    "ratio = np.where(newpdf[k]<1.e-5,0,ratio)\n",
    "plt.plot(newz, ratio,'.')\n",
    "#plt.xlim((0.19,0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-public",
   "metadata": {},
   "source": [
    "In the residual plot above, the large values occur at the transition where both the intial and reconstructed pdf reach 0, and thus is a numerical artefact without serious consequences.\n",
    "\n",
    "It is important to note that the sparse representation is *not* a functional representation : the reconstructed pdf is evaluated at the grid of points used to build the matrix *A*. Interpolation is required in a scheme where the reconstructed pdf needs to be evaluated anywhere, as in qp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-somewhere",
   "metadata": {},
   "source": [
    "In the case where qp reads a file with a sparse encoding of the objects, the matrix A will not be available, and needs to be rebuilt based on the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = qp.sparse_rep.create_voigt_basis(meta['xvals'], meta['mu'], meta['dims'][0], meta['sig'], meta['dims'][1]\\\n",
    "                                , meta['dims'][2], cut=1.e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-plain",
   "metadata": {},
   "source": [
    "If needed, one can also retrieve the shape parameters of the Voigt representations, and use these to reconstruct the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next decode the sparse indices into the voigt shape parameters\n",
    "wa, ma, sa, ga = qp.sparse_rep.indices2shapes(Sparse_Indices, meta)\n",
    "pdf_shape = qp.sparse_rep.shapes2pdf(wa[k], ma[k], sa[k], ga[k], meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(pdf_shape,pdf_y[:,k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing to a fits file, as originally proposed in SparsePz\n",
    "if False:\n",
    "    print('Writing fits file (example_out.fits)')\n",
    "\n",
    "    head = pf.Header()\n",
    "    head['N_TOT'] = Ntot\n",
    "    head['N_MU'] = bigD['dims'][0]\n",
    "    head['N_SIGMA'] = bigD['dims'][1]\n",
    "    head['N_VOIGT'] = bigD['dims'][2]\n",
    "    head['N_COEF'] = bigD['dims'][3]\n",
    "    head['N_SPARSE'] = bigD['N_SPARSE']\n",
    "    head['MU1'] = bigD['mu'][0]\n",
    "    head['MU2'] = bigD['mu'][1]\n",
    "    head['SIGMA1'] = bigD['sig'][0]\n",
    "    head['SIGMA2'] = bigD['sig'][1]\n",
    "\n",
    "    col1 = pf.Column(name='redshift', format='E', array=bigD['z'])\n",
    "    fmt = '%dJ' % bigD['N_SPARSE']\n",
    "    col2 = pf.Column(name='Sparse_indices', format=fmt, array=ALL)\n",
    "    table1 = pf.BinTableHDU.from_columns(pf.ColDefs([col1]))\n",
    "    table2 = pf.BinTableHDU.from_columns(pf.ColDefs([col2]))\n",
    "    prihdu = pf.PrimaryHDU(header=head)\n",
    "    hdulist = pf.HDUList([prihdu, table1, table2])\n",
    "    hdulist.writeto('example_out.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "myMeta = dict(xvals=meta['xvals'], mu=meta['mu'], sig=meta['sig'], N_SPARSE=meta['N_SPARSE'], dims=meta['dims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we can also create a qp ensemble\n",
    "ens_sparse = qp.Ensemble(qp.sparse, data=dict(sparse_indices=Sparse_Indices, **myMeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(newz, newpdf[8], linewidth=2)\n",
    "plt.plot(meta['xvals'], ens_sparse.pdf(meta['xvals'])[8])\n",
    "#interpolation works\n",
    "newx = np.linspace(0.005,1.8,300)\n",
    "plt.plot(newx, ens_sparse.pdf(newx)[8], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is broken\n",
    "ens_sparse.plot(key=8, xlim=(0, 1.8), label=\"PDF 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also turn the gridded initial representation (the input file) into the sparse representation by conversion.\n",
    "ens_sparse = qp.convert(ens_red, 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_sparse.plot(key=8, xlim=(0, 1.8), label=\"PDF 1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
