{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook\n",
    "[`bayesian_optimization_blooper.ipynb`](bayesian_optimization_blooper.ipynb), we ran\n",
    "into some unexpected results. Bayesian optimization was on par with grid search, and\n",
    "random search was the best? See below.\n",
    "\n",
    "![blooper](bayesian_optimization_blooper.png)\n",
    "\n",
    "To help troubleshoot the source of the unexpected\n",
    "behavior, we'll move the schedule up and use a simulator. The large stochasticity for\n",
    "identical inputs shown at the end of the last notebook is a cause for concern.\n",
    "\n",
    "|  | mean | std |\n",
    "|---|---|---|\n",
    "| ch415_violet | 17928.500000 | 25288.711738 |\n",
    "| ch445_indigo | 8746.200000 | 9379.586248 |\n",
    "| ch480_blue | 19396.100000 | 17832.023101 |\n",
    "| ch515_cyan | 4870.900000 | 12126.813252 |\n",
    "| ch560_green | 11908.300000 | 18944.797128 |\n",
    "| ch615_yellow | 18406.400000 | 19626.981147 |\n",
    "| ch670_orange | 30584.100000 | 20868.707815 |\n",
    "| ch720_red | 5776.100000 | 9066.354228 |\n",
    "| ch_clear | 1294.100000 | 2017.116669 |\n",
    "| ch_nir | 0.000000 | 0.000000 |\n",
    "| mae | 13798.390000 | 2959.743242 |\n",
    "| rmse | 23851.888103 | 3422.810056 |\n",
    "\n",
    "Is the stochasticity due to excessive noise from too short of integration time or is it\n",
    "a problem with the hardware such as a sensor malfunction? Based on inspection from my\n",
    "own eyes, fixed inputs appeared to produce very similar colors. Last, this could be due\n",
    "to (intentional) naive design decision of starting out with mean absolute error for the\n",
    "objective function rather than something more tuned to this problem, such as Wasserstein\n",
    "distance between the two discrete spectra. In reality, it's probably some mix and\n",
    "interplay of the previous issues:\n",
    "\n",
    "- **(epistemic) uncertainty**\n",
    "  - i.e. just a part of the system, solved by a longer integration time (more data)\n",
    "- **sensor malfunction/degradation**\n",
    "  - due to blasting it repeatedly with a bright DotStar\n",
    "  - and/or hard device resets due to system crashes\n",
    "  - and/or or (just remembered!) a series\n",
    "  of recent unexpected power outages for my housing community\n",
    "- **Poorly defined objective function**\n",
    "  - It was defined in a way that it doesn't handle stochastic bias when\n",
    "  a signal is measured in an adjacent channel, solved by using a robust distance metric\n",
    "  for discrete distributions (e.g. Wasserstein)\n",
    "- **Something else?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My wife kindly reminded me of past lessons learned during experimentation, and\n",
    "encouraged me to try out the simulation. So, let's do that here! We'll take a look at\n",
    "our domain knowledge / assumptions for the simulation, briefly describe the approach,\n",
    "and then dig into a snapshot of the `SensorSimulator` class. Finally, we'll demonstrate\n",
    "the usage and run our grid vs. random vs. Bayesian search algorithm comparison with our\n",
    "simulation.\n",
    "\n",
    "\n",
    "## Domain Knowledge\n",
    "\n",
    "> TLDR; extract the data from the DotStar RGB spectrum listed in the [manufacturer's datasheet](https://cdn-shop.adafruit.com/product-files/2343/SK9822_SHIJI.pdf)\n",
    "\n",
    "A basic physics course teaches the wave-particle duality of light. Light can be thought\n",
    "of as a wave (signal with frequency/wavelength) or as a particle (photon). In the case\n",
    "of designing a (very basic) simulation for an RGB LED spectrum being read by a\n",
    "discrete-channel sensor, we focus mainly on the wave portion of wave-particle duality of\n",
    "light. Most light-emitting-diodes (LEDs) have fairly narrow distributions of wavelengths\n",
    "that they emit like what's shown in the following image from the [DotStar manufacturer's datasheet](https://cdn-shop.adafruit.com/product-files/2343/SK9822_SHIJI.pdf).\n",
    "\n",
    "<img src=\"../reports/figures/dotstar/rgb-relative-emission-vs-wavelength.png\" width=350>\n",
    "\n",
    "Controlling the brightness and RGB values of our LED controls the relative contribution\n",
    "of each of the three distributions portrayed above. Meanwhile, our spectrophotometer (a device that measures the intensity of light at various\n",
    "wavelengths) measures the light intensity at 8 wavelengths (it also has \"clear\" and\n",
    "\"near infrared\" channels that we'll ignore):\n",
    "\n",
    "| wavelength | intensity |\n",
    "|---|---|\n",
    "415 nm | Violet\n",
    "445 nm | Indigo or Blue\n",
    "480 nm | Blue or Blue-Green\n",
    "515 nm | Blue-Green or Green\n",
    "555 nm | Green or Yellow-Green \n",
    "590 nm | Yellow-Green or Yellow\n",
    "630 nm | Orange or Orange-Red or Red\n",
    "680 nm | Red\n",
    "\n",
    "We can digitize the data from the manufacturer datasheet using\n",
    "[WebPlotDigitizer](https://automeris.io/WebPlotDigitizer/) and then use that for\n",
    "calculating/mixing an arbitrary spectrum based on brightness and RGB settings. We'll make the\n",
    "reasonable approximation/assumption that the [superposition principle](https://en.wikipedia.org/wiki/Superposition_principle) applies*. In other\n",
    "words, we assume that the individual spectra from the red, green, and blue LEDs can be\n",
    "added together. Below is a screenshot of the datapoints extracted via the\n",
    "WebPlotDigitizer interface for each of the three curves. Corresponding `.csv` files are\n",
    "also saved: [`red.csv`](../src/self_driving_lab_demo/data/red.csv), [`green.csv`](../src/self_driving_lab_demo/data/green.csv), and [`blue.csv`](../src/self_driving_lab_demo/data/blue.csv).\n",
    "\n",
    "<img src=\"../src/self_driving_lab_demo/data/wpd-rgb-spectrum-points-overlay.png\"\n",
    "width=350>\n",
    "\n",
    "See [RGB LEDs vs. having 10+ monochromatic light\n",
    "sources](https://github.com/sparks-baird/self-driving-lab-demo/issues/6) for more\n",
    "details on the hardware design considerations for the LEDs and sensor.\n",
    "\n",
    "<p><sup>\n",
    "*While it would be interesting to look at optimization setups that\n",
    "involve light cancellation, the equipment required is likely not within the budget\n",
    "and time constraints of the self-driving-lab-demo project (less than 100 USD and less\n",
    "than an hour of setup time).\n",
    "</p></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Simulation Details\n",
    "\n",
    "As mentioned, we'll mix the three spectra extracted from the manufacturer datasheet\n",
    "according to the simulation inputs (brightness\n",
    "and RGB values). After loading the CSV data, we'll clip any data below 0.0 and average\n",
    "the intensities that are not one-to-one (i.e. multiple intensities for the same\n",
    "wavelength) due to the data extraction process. Next, we'll use `scipy`'s `interp1d`\n",
    "function for each of the three color spectra to create linear interpolation functions\n",
    "which are set to zero outside of the range of the original data (extrapolation).\n",
    "Finally, we'll calculate a weighted sum of each of the interpolators as a function of\n",
    "brightness and RGB sampled at each of the wavelengths mentioned above.\n",
    "\n",
    "A more sophisticated setup might involve sampling a distribution of wavelengths for each\n",
    "channel; however, we'll keep it simple for now.\n",
    "\n",
    "## Sensor Simulator Python class\n",
    "Below is a snapshot of the `SensorSimulator` class, broken into chunks.\n",
    "\n",
    "First, we need our imports and define the wavelengths we'll be sampling at as a constant.\n",
    "\n",
    "```python\n",
    "from importlib.resources import open_text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from self_driving_lab_demo import data as data_module\n",
    "\n",
    "CHANNEL_WAVELENGTHS = [\n",
    "    415,\n",
    "    445,\n",
    "    480,\n",
    "    515,\n",
    "    560,\n",
    "    615,\n",
    "    670,\n",
    "    720,\n",
    "]\n",
    "```\n",
    "\n",
    "The class doesn't take any keyword arguments (again, keeping it simple), and when the\n",
    "class is instantiated, it creates an interpolator.\n",
    "\n",
    "```python\n",
    "class SensorSimulator(object):\n",
    "    def __init__(self):\n",
    "        self.red_interp = self.create_interpolator(\"red.csv\")\n",
    "        self.green_interp = self.create_interpolator(\"green.csv\")\n",
    "        self.blue_interp = self.create_interpolator(\"blue.csv\")\n",
    "\n",
    "```\n",
    "\n",
    "We make it easy to get the channel wavelengths (making it a constant outside the class\n",
    "makes it easily accessible for other modules).\n",
    "\n",
    "```python\n",
    "    @property\n",
    "    def channel_wavelengths(self):\n",
    "        return CHANNEL_WAVELENGTHS\n",
    "```\n",
    "\n",
    "The data is read using best practices (`open_text` using Python modules), negative\n",
    "values are clipped, and y-values with repeat x-values are averaged. Finally, the\n",
    "`interp1d` uses a linear interpolation (`cubic` gave some outlandish values during\n",
    "testing) and zero-ing extrapolation (zero anywhere outside the range of the original\n",
    "dataset). This is done separately for each of the red, green, and blue curves.\n",
    "\n",
    "```python\n",
    "    def create_interpolator(self, fname):\n",
    "        df = pd.read_csv(\n",
    "            open_text(data_module, fname),\n",
    "            header=None,\n",
    "            names=[\"wavelength\", \"relative_intensity\"],\n",
    "        )\n",
    "\n",
    "        df[\"relative_intensity\"].clip(lower=0.0, inplace=True)\n",
    "\n",
    "        # average y-values for repeat x-values\n",
    "        # see also https://stackoverflow.com/a/51258988/13697228\n",
    "        df = df.groupby(\"wavelength\", as_index=False).mean()\n",
    "\n",
    "        return interp1d(\n",
    "            df[\"wavelength\"],\n",
    "            df[\"relative_intensity\"],\n",
    "            kind=\"linear\",\n",
    "            bounds_error=False,\n",
    "            fill_value=0.0,\n",
    "        )\n",
    "\n",
    "```\n",
    "\n",
    "To perform the weighted average (mixing) of spectra, we divide the RGB values by 255\n",
    "(this is arbitrary) and multiply by the brightness. This is then multipled by the\n",
    "interpolated value at each of the wavelengths. Finally, we sum the contribution of each\n",
    "of the wavelengths.\n",
    "\n",
    "```python\n",
    "    def _simulate_sensor_data(self, wavelengths, brightness, R, G, B):\n",
    "        rI, gI, bI = brightness * np.array([R, G, B]) / 255\n",
    "        channel_data = np.sum(\n",
    "            [\n",
    "                self.red_interp(wavelengths) * rI,\n",
    "                self.green_interp(wavelengths) * gI,\n",
    "                self.blue_interp(wavelengths) * bI,\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tuple(channel_data)\n",
    "```\n",
    "\n",
    "Last, we define a class method that fixes the wavelengths to the constant mentioned before.\n",
    "\n",
    "```python\n",
    "    def simulate_sensor_data(self, brightness, R, G, B):\n",
    "        return self._simulate_sensor_data(self.channel_wavelengths, brightness, R, G, B)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdl-demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5c3f3d11f10387e18d251eb902c90d66624c3f38140e2cc8c3a7a1864ed0fae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
