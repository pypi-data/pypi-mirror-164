{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "paraDime is a flexible framework for specifiying parametric dimensionality reduction *routines*. A routine basically consists of a neural network, a dataset, and some instructions about what exactly paraDime should do yith your data to reduce its dimensionality.\n",
    "\n",
    "paraDime has a flexible API with several predefined classes for each part of a routine, and each part can be fully customized by extending these existing classes. If you want to learn more about what exactly makes up a routine, see the [Building Blocks](building_blocks.rst) page.\n",
    "\n",
    "But for now, the easiest way to get started with paraDime is to use on of the predefined routines. In the following short tutorial, we are going to train one of the predefined paraDime routines to reduce the dimensionality of data from the MNIST dataset of handwritten digits.\n",
    "\n",
    "## Importing paraDime and Loading the Dataset\n",
    "\n",
    "First, we import the ``routines`` submodule of paraDime, which includes the predefined routines. We also import paraDime's ``utils`` subpackage, which implements a scatterplot function that we are later going to use. Finally, we import torchvision, which gives us convenient access to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paradime.routines\n",
    "import paradime.utils\n",
    "import torchvision\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(\n",
    "    '../data',\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "mnist_data = mnist.data.reshape(-1, 28*28) / 255.\n",
    "num_items = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have already flattened the image data into vectors of length 784 and normalized the values to a range between 0 and 1. ``num_items`` is the size of the MNIST subset that we are going to use for training our routine.\n",
    "\n",
    "## Setting Up a Predefined Routine\n",
    "\n",
    "We now create an instance of a parametric version of the t-SNE algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = paradime.routines.ParametricTSNE(\n",
    "    perplexity=100,\n",
    "    dataset=mnist_data[:num_items],\n",
    "    epochs=40,\n",
    "    use_cuda=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When initializing a routine, paraDime only needs minimal information to set up the underlying neural network. In this case paraDime infers all the necessary information from the dataset that we pass. For more info on the default model construction, see the section about [Models](building_blocks.rst#model). We tell paraDime that the main part of the traingin should go on for 40 epochs, and we would like to use the GPU for training (use ``use_cuda = False`` or comment out this line, if you don't have CUDA installed.) Finally, the ``verbose`` flag tells paraDime to log some information about what is going on behind the scenes.\n",
    "\n",
    "You might have noticed that we also pass a ``perplexity`` value, which is specific to the t-SNE algorithm.\n",
    "\n",
    "Training the Routine and Visualizing the Results\n",
    "------------------------------------------------\n",
    "\n",
    "Since any other necessary bulding blocks are already predefined in this case, all that's left to do is to train the model. To do this, we simply call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training is done, we can apply our trained model to the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = dr.apply(mnist_data[:num_items])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the dimensionality-reduced version of the data that we used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradime.utils.plotting.scatterplot(reduced, mnist.targets[:num_items])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because paraDime models are parametric, you can easily apply the trained model to the whole MNIST dataset, even though our routine only ever saw a small subset of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradime.utils.plotting.scatterplot(dr.apply(mnist_data), mnist.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to configure our own paraDime routines, you will need to get an understandin of what was going on behind the scenes. The output log might have given you a first idea about the different parts and steps involved in a routine. All the details are explained in the section about the [Building Blocks of a ParaDime Routine](building_blocks.rst)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7c9f3c5c5217e50e8596266617689c08e27d4baf18921dd4598144a1d3a89bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
