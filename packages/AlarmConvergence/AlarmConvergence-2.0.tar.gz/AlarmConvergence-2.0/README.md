# **AlarmConvergence**

###@Mihuier

AlarmConvergence是一个关于告警治理与收敛问题的实习项目。该项目利用AIOps手段集中化解决业务变更导致的告警风暴、找出相似和关联告警。旨在帮助运维人员在收到告警时，快速定位到故障的大致方向，从而提高故障排查的效率。本方法通过对一段时间内的告警进行聚类收敛处理，根据运维告警关键属性找出泛化报警，最终形成仅有几条泛化告警的告警摘要。AlarmConvergence项目包括两套方案：静态（历史）数据收敛方案和动态（流式）数据收敛方案。

## 安装

方式1：
```
$ python setup.py install --user
```

方式2：
```
$ sudo python setup.py install
```

方式3：
```
$ pip install AlarmConvergence --user
```

方式4：
```
$ sudo pip install AlarmConvergence
```

Python 3下需要将上面的python改成python3，pip改成pip3。


## 卸载
```plain
$ pip uninstall AlarmConvergence
```

## 依赖
Python 2.8.1                   
Pandas 1.2.4             
Jieba >= 0.35  
Numpy >= 1.7.1  
Networkx >= 1.9.1  

## 兼容性
Python 3.8.8中测试通过。


##静态数据收敛方案



静态（历史）数据告警收敛过程分为4个步骤：


- Step1：资源对象与告警内容属性的关键字提取；
- Step2：定义时间窗口；
- Step3：计算时间窗口内相邻告警的相似度； 
- Step4：收敛时间窗口内满足一定相似度的告警并输出摘要。

### 1.1 Extract\_keywards
本过程使用TextRank提取关键字,TextRank的详细原理请参考：

> Mihalcea R, Tarau P. TextRank: Bringing order into texts[C]. Association for Computational Linguistics, 2004.

关于TextRank的原理和使用介绍：[使用TextRank算法为文本生成关键字和摘要](https://www.letiantian.me/2014-12-01-text-rank/)

- 关键词提取：
将告警内容和资源对象合并本拆分为句子，在每个句子中过滤掉停用词（可选），并只保留指定词性的单词（可选）。由此可以得到句子的集合和单词的集合。
每个单词作为pagerank中的一个节点。设定窗口大小为k，假设一个句子依次由下面的单词组成：
```
w1, w2, w3, w4, w5, ..., wn
```
`w1, w2, ..., wk`、`w2, w3, ...,wk+1`、`w3, w4, ...,wk+2`等都是一个窗口。在一个窗口中的任两个单词对应的节点之间存在一个无向无权的边。
基于上面构成图，可以计算出每个单词节点的重要性。最重要的若干单词可以作为关键词。


* 关键短语提取：
参照[关键词提取](#关键词提取)提取出若干关键词。若原文本中存在若干个关键词相邻的情况，那么这些关键词可以构成一个关键词组。
例如，在一篇介绍`支持向量机`的文章中，可以找到关键词`支持`、`向量`、`机`，通过关键词组提取，可以得到`支持向量机`。

* 摘要生成：
将每个句子看成图中的一个节点，若两个句子之间有相似性，认为对应的两个节点之间有一个无向有权边，权值是相似度。
通过pagerank算法计算得到的重要性最高的若干句子可以当作摘要。


### 1.2. Time\_transform
将首次发生时间转换为时间戳格式，计算相邻告警的时间差

### 1.3. Similarity\_calculation
利用Jaccard相似系数衡量文本相似度，给定两个集合A,B，Jaccard 系数定义为A与B交集的大小与A与B并集的大小的比值。与Jaccard 系数相关的指标叫做Jaccard 距离，用于描述集合之间的不相似度。Jaccard 距离越大，样本相似度越低。

### 1.4. Highlight\_2min\_0.8sim
收敛2min时间窗口内满足相似度80%以上的告警并输出摘要

##动态数据收敛方案
- 对一段时间内的报警依据生产部署拓扑根因进行聚类收敛处理，根据告警内容找出泛化报警，最终形成仅有几条泛化告警的告警摘要。选定Bert预训练模型和层次聚类模型结合，给出了针对告警聚类的一种具体的实现方案。在分布式业务服务的系统下构造了验证了算法的效果。

- 动态（流式）数据收敛全过程包括收集告警信息、提取告警信息的关键特征、聚类处理、展示告警摘要。


### 2.1. Classify_Model
- 我们可以将这几条报警抽象为：“自定义业务 CRM五项考核 数据库故障”，该泛化报警包含的范围较广；也可以抽象为：“CRM服务器 业务失败量”获取产品类型信息失败”，此时包含的范围较小。当然也可以用其他层次的抽象来表达这个报警集群。可以观察到，抽象层次越高，细节越少，但是它能包含的范围就越大；反之，抽象层次越低，则可能无用信息越多，包含的范围就越小。这种抽象的层次关系可以用一些有向无环图（DAG）来表达


### 2.2. SVM
- 完成静态数据收敛方案后，每类告警均被打上标签，将该类带有标签的数据进行有监督训练，从而得到一个自动告警类别判定模型。这里的有监督模型使用的是SVM, SVM 的本质就是想要画出一条线，以“最好地”区分这各类点，以至如果以后有了新的点，这条线也能做出很好的分类。

- 如何找到最合适的分类超平面？依据的原则就是间隔最大化。所谓间隔最大化，说的是分类超平面跟两类数据的间隔要尽可能大（即远离两边数据），这就要提到我们前面说到的公平原则。“三八线”要划在课桌正中间，不偏向任何一方，才能保证双方利益最大化。对于分类超平面来说，也就是要位于两类数据的正中间，不偏向任何一类，才能保证离两边数据都尽可能远，从而实现间隔最大化。


## 使用说明
1.本方案针对实际生产运维环境个性化设计，数据集不公开。


2.类TextRank4Keyword、TextRank4Sentence在处理一段文本时会将文本拆分成4种格式：

* sentences：由句子组成的列表。
* words_no_filter：对sentences中每个句子分词而得到的两级列表。
* words_no_stop_words：去掉words_no_filter中的停止词而得到的二维列表。
* words_all_filters：保留words_no_stop_words中指定词性的单词而得到的二维列表。

## 实例
例如，对于文本1：

* 资源对象 ——
```自定义业务:【CRM五项考核】统一积分平台交易及时率—积分自有业务订单下发应答未反馈—T5000040-请立即手工反馈
```

* 告警内容 ——
```
实时检查,数据库表统计结果大于0,当前值为1
```

* 关键字提取结果 ——
```
反馈 检查 业务 实时 统一 平台 订单 应答 下发 数据库
```

* 输出摘要 ——
```
数据库业务告警
```

文本2：

* 
```
这间酒店位于北京东三环，里面摆放很多雕塑，文艺气息十足。答谢宴于晚上8点开始。
```

* 运行结果如下：
```plain sentences:
这间酒店位于北京东三环，里面摆放很多雕塑，文艺气息十足
答谢宴于晚上8点开始;
words_no_filter:
这/间/酒店/位于/北京/东三环/里面/摆放/很多/雕塑/文艺/气息/十足
答谢/宴于/晚上/8/点/开始;
words_no_stop_words:
间/酒店/位于/北京/东三环/里面/摆放/很多/雕塑/文艺/气息/十足
答谢/宴于/晚上/8/点;
words_all_filters:
酒店/位于/北京/东三环/摆放/雕塑/文艺/气息
答谢/宴于/晚上;

```


## API
TODO.

类的实现、函数的参数请参考源码注释。

## License
[MIT](./LICENSE)









