# AUTOGENERATED! DO NOT EDIT! File to edit: ../03_taxi_problem.ipynb.

# %% auto 0
__all__ = ['env', 'QLearning']

# %% ../03_taxi_problem.ipynb 16
import gym
import gym_duckienav
import gym.spaces
import numpy as np

env = gym.make("DuckieNav-v2")

# %% ../03_taxi_problem.ipynb 53
def QLearning(env, episodes = 10000, alpha = 0.618):
    n_states = env.observation_space.n
    n_actions = env.action_space.n
    Q = np.zeros([n_states, n_actions])
    ACTIONS = ["South", "North", "East", "West", "Pickup", "Dropoff"]

    rewardTracker = []

    G = 0
    
    for episode in range(1,episodes+1):
        done = False
        G, reward = 0,0

        state = env.reset()

        while done != True:
            action = np.argmax(Q[state]) 
            state2, reward, done, info = env.step(action) 
            Q[state,action] += alpha * ((reward + (np.max(Q[state2]))  - Q[state,action]))
            G += reward
            state = state2

        if episode % 100 == 0:
            print('Episode {} Total Reward: {}'.format(episode,G))

    print(str(np.count_nonzero(Q)), " / ", str(n_states * n_actions))
